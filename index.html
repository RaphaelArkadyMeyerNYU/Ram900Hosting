<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="/css/theorem.css"> <link rel=stylesheet  href="/css/algorithm.css"> <link rel=icon  href="/assets/favicon.ico"> <title>Raphael A. Meyer</title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> <li><a href="/assets/raphael_a_meyer_cv.pdf">CV</a> <li><a href="/hutchplusplus" style="padding: 10px 8px">Hutch++</a> <li><a href="/siam-nnp-minisymposium-2023" style="padding: 10px 0px">SIAM-NNP</a> </ul> </div> <div id=main > <div class=franklin-content ><h1 id=raphael_arkady_meyer ><a href="#raphael_arkady_meyer" class=header-anchor >Raphael Arkady Meyer</a></h1> <div class=row ><div class=container ><div class=left ><img src="/assets/profile_2022.jpg" alt="" /></div></div> <p>I am a final year Ph.D. Student at NYU Tandon School of Engineering, advised by <a href="https://www.chrismusco.com">Christopher Musco</a> and part of the <a href="https://csefoundations.engineering.nyu.edu/">Algorithms and Foundations Group</a>.</p> <p>I research the interplay of theoretical statistics and computation, largely through the lens of linear algebra.</p> <p>In the summer of 2022, I visited <a href="https://theory.epfl.ch/kapralov/">Michael Kapralov&#39;s</a> group at EPFL and <a href="http://www.math.tau.ac.il/~haimav/">Haim Avron&#39;s</a> group at TAU.</p></div> <p>Links: <a href="https://scholar.google.com/citations?user&#61;Xpi5HD0AAAAJ">Google Scholar</a>, <a href="https://dblp.org/pid/204/4381.html">dblp</a>, <a href="https://github.com/RaphaelArkadyMeyerNYU">Github</a>, <a href="https://nyu.zoom.us/my/ram900">Zoom Room</a></p> <p>My recent publications have looked at:</p> <ul> <li><p>Fast Numerical Linear Algebra &#40;<em><a href="https://arxiv.org/abs/2309.04952">preprint</a></em>, <em><a href="https://arxiv.org/abs/2309.04952">preprint</a></em>, <em><a href="https://arxiv.org/abs/2305.02535">SODA2024</a></em>&#41;</p> <li><p>Active Learning on Linear Function Families &#40;<em><a href="https://arxiv.org/abs/2211.06790">SODA2023</a></em>, <em><a href="https://arxiv.org/pdf/2006.08035.pdf">NeurIPS2020</a></em>&#41;</p> </ul> <p>Of course, I am interested in problems beyond these areas, and if you want to work with me on a problem, send me an email: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>a</mi><mi>m</mi><mn>900</mn><mi mathvariant=normal >@</mi><mi>n</mi><mi>y</mi><mi>u</mi><mi mathvariant=normal >.</mi><mi>e</mi><mi>d</mi><mi>u</mi></mrow><annotation encoding="application/x-tex">ram900@nyu.edu</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class=mord >9</span><span class=mord >0</span><span class=mord >0</span><span class=mord >@</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">u</span><span class=mord >.</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">u</span></span></span></span></p> <h1 id=news ><a href="#news" class=header-anchor >News</a></h1> <ul> <li><p><img style="width:25px;height:18px;padding-left:0", src="/assets/knuths-new.gif"> New preprint on arXiv: <a href="https://arxiv.org/abs/2311.14023"><em>Algorithm-Agnostic Low-Rank Approximation of Operator Monotone Matrix Functions</em></a>.</p> <li><p>Paper accepted at SODA 2024: <em><a href="https://arxiv.org/abs/2305.02535">On the Unreasonable Effectiveness of Single Vector Krylov Methods for Low-Rank Approximation</a></em>&#33;</p> </ul> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mphantom><mi mathvariant=normal >.</mi></mphantom></mrow><annotation encoding="application/x-tex">\phantom{.}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.10556em;vertical-align:0em;"></span><span class=mord  style="color:transparent;">.</span></span></span></span> <button class=theorem-accordion ><div class=theorem-accordion-text > <em>Old News</em> </div></button><div class=theorem-panel ><p></p> <p>November 2023</p> <ul> <li><p>I gave a talk on <a href="https://arxiv.org/abs/2305.02535">Krylov methods</a> at the <a href="https://www.math.purdue.edu/~xiaj/FastSolvers2023/index.html">Conference on Fast Direct Solvers</a> at Purdue University in November.</p> <li><p>I gave a <a href="https://orecchia.net/event/theory-lunch/">talk at UChicago</a> on <a href="https://arxiv.org/abs/2010.09649">Trace Estimation</a> and <a href="https://arxiv.org/abs/2309.04952">Kronecker-Trace Estimation</a> on November 1st.</p> </ul> <p>October 2023</p> <ul> <li><p>I organized a minisymposium on <em>The Matrix-Vector Complexity of Linear Algebra</em> at the first ever <a href="https://sites.google.com/view/siam-nynjpa/annual-meeting">SIAM-NNP conference</a>&#33;</p> <p><a href="https://sites.google.com/view/shyamnarayanan/home">Shyam Narayanan</a>, <a href="https://e.math.cornell.edu/people/halikias/">Diana Halikias</a>, <a href="https://wswartworth.github.io/">William Swartworth</a>, <a href="https://chen.pw/">Tyler Chen</a>, and myself were presenting at 8:30am on Sunday. What a stacked lineup&#33; <strong>See the details here: <a href="/siam-nnp-minisymposium-2023">link</a>.</strong></p> </ul> <p>September 2023</p> <ul> <li><p>New preprint on arXiv: <a href="https://arxiv.org/abs/2309.04952"><em>Hutchinson’s Estimator is Bad at Kronecker-Trace-Estimation</em></a>.</p> </ul> <p>May 2023</p> <ul> <li><p>New preprint on arXiv: <a href="https://arxiv.org/abs/2305.02535"><em>On the Unreasonable Effectiveness of Single Vector Krylov Methods for Low-Rank Approximation</em></a>.</p> </ul> <p>March 2023</p> <ul> <li><p>I gave two talks at the NYU / UMass Quantum Linear Algebra reading group.</p> <li><p>I gave a talk at the BIRS Perspectives on Matrix Computations about my <a href="https://arxiv.org/abs/2305.02535"><em>new work on Krylov methods</em></a>.</p> </ul> <p>January 2023</p> <ul> <li><p>I presented <a href="https://arxiv.org/abs/2211.06790"><em>Near-Linear Sample Complexity for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> Polynomial Regression</em></a> at SODA 2023.</p> </ul> <p>November 2022</p> <ul> <li><p>I gave a talk at the <a href="https://theorypurdue.wordpress.com/">TCS Seminar at Purdue</a> in early November to present my new research on the role of block size in Krylov Methods.</p> </ul> <p>October 2022</p> <ul> <li><p>New paper accepted at SODA 2023: <em>Near-Linear Sample Complexity for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> Polynomial Regression</em>&#33; I just gave a talk on it last week Friday at the Grad Student Seminar at CDS &#40;at NYU&#41;.</p> </ul> <p>September 2022</p> <ul> <li><p>I gave a talk at <a href="https://sites.google.com/view/gammanla2022/home">GAMM ANLA</a> on the role of block size in Krylov Methods for low-rank approximation. A preprint will be available very soon, but until then you can check out my slides for a preview&#33; <a href="/assets/svkGammAnla20minBeamers.pdf">Slides</a></p> </ul> <p>July 2022</p> <ul> <li><p>I gave a talk at the <em>SIAM Annual Meeting Minisymposium on Matrix Functions, Operator Functions, and Related Approximation Methods</em>. Thanks to Heather, Andrew, and Ke for organizing&#33;</p> </ul> <p>June 2022</p> <ul> <li><p>I&#39;m going be presenting Hutch&#43;&#43; this summer at <a href="https://www.lse.ac.uk/HALG-2022">HALG2022</a>, with both a short talk and a poster.</p> <li><p>I&#39;m traveling this summer&#33; I&#39;m first in London for <a href="https://www.lse.ac.uk/HALG-2022">HALG2022</a>. Then I&#39;m spending June visiting <a href="http://www.math.tau.ac.il/~haimav/">Haim Avron</a> at <a href="https://english.tau.ac.il/">TAU</a>, and July visiting <a href="https://theory.epfl.ch/kapralov/">Michael Kapralov</a> at <a href="https://www.epfl.ch/en/">EPFL</a>. If you&#39;re in the same place at the same time, <a href="mailto:ram900@nyu.edu">drop me a line</a>&#33;</p> </ul> <p>May 2022</p> <ul> <li><p>I recently organized a mini-conference for NYU CS Theory researchers to present their &quot;Pandemic Papers&quot; in-person. Thanks to everyone who showed up and made it a success&#33; <a href="/tcs_presentations"><em>More details here</em></a></p> <li><p>I&#39;m honored to be awarded the <strong>Deborah Rosenthal, MD Award for Best Quals Examination</strong> in 2022, for my presentation <em>Towards Optimal Spectral Sum Estimation in the Matrix-Vector Oracle Model</em>.</p> </ul> <p>April 2022</p> <ul> <li><p>I&#39;m honored to be a ICLR 2022 Highlighted Reviewer.</p> </ul> <p></p></div> <h1 id=publications ><a href="#publications" class=header-anchor >Publications</a></h1> <div class=link-hover-only ><ol> <li><p><a href="https://arxiv.org/abs/2311.14023"><strong>Algorithm-Agnostic Low-Rank Approximation of Operator Monotone Matrix Functions</strong></a></p> <span class=fakeclass > in submission <em>with <a href="https://scholar.google.com/citations?user&#61;jOtDnRAAAAAJ&amp;hl&#61;en&amp;oi&#61;ao">David Persson</a> and <a href="https://www.chrismusco.com/">Christopher Musco</a></em></span> <li><p><a href="https://arxiv.org/abs/2309.04952"><strong>Hutchinson&#39;s Estimator is Bad at Kronecker-Trace-Estimation</strong></a><sup id="fnref:KronHutchinsonAssets"><a href="#fndef:KronHutchinsonAssets" class=fnref >[1]</a></sup></p> <span class=fakeclass > in submission <em>with <a href="http://www.math.tau.ac.il/~haimav/">Haim Avron</a></em></span> <li><p><a href="https://arxiv.org/abs/2305.02535"><strong>On the Unreasonable Effectiveness of Single Vector Krylov Methods for Low-Rank Approximation</strong></a><sup id="fnref:SODA2024assets"><a href="#fndef:SODA2024assets" class=fnref >[2]</a></sup></p> <span class=fakeclass > at SODA 2024 <em>with <a href="https://people.cs.umass.edu/~cmusco/">Cameron Musco</a> and <a href="https://www.chrismusco.com/">Christopher Musco</a></em></span> <li><p><a href="https://arxiv.org/abs/2211.06790"><strong>Near-Linear Sample Complexity for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> Polynomial Regression</strong></a><sup id="fnref:SODA2023assets"><a href="#fndef:SODA2023assets" class=fnref >[3]</a></sup></p> <span class=fakeclass > at SODA 2023 <em>with <a href="https://people.cs.umass.edu/~cmusco/">Cameron Musco</a>, <a href="https://www.chrismusco.com/">Christopher Musco</a>, <a href="http://www.cs.cmu.edu/~dwoodruf/">David P. Woodruff</a>, and <a href="https://samsonzhou.github.io/">Samson Zhou</a></em></span> <li><p><a href="https://arxiv.org/abs/2203.07557"><strong>Fast Regression for Structured Inputs</strong></a><sup id="fnref:ICLR2022assets"><a href="#fndef:ICLR2022assets" class=fnref >[4]</a></sup></p> <span class=fakeclass > at ICLR 2022 <em>with <a href="https://people.cs.umass.edu/~cmusco/">Cameron Musco</a>, <a href="https://www.chrismusco.com/">Christopher Musco</a>, <a href="http://www.cs.cmu.edu/~dwoodruf/">David P. Woodruff</a>, and <a href="https://samsonzhou.github.io/">Samson Zhou</a></em></span> <li><p><a href="https://arxiv.org/abs/2010.09649"><strong>Hutch&#43;&#43;: Optimal Stochastic Trace Estimation</strong></a><sup id="fnref:hutchassets"><a href="#fndef:hutchassets" class=fnref >[5]</a></sup></p> <span class=fakeclass > at SOSA 2021 <em>with <a href="https://people.cs.umass.edu/~cmusco/">Cameron Musco</a>, <a href="https://www.chrismusco.com/">Christopher Musco</a>, and <a href="http://www.cs.cmu.edu/~dwoodruf/">David P. Woodruff</a></em></span> <li><p><a href="https://arxiv.org/abs/2006.08035"><strong>The Statistical Cost of Robust Kernel Hyperparameter Tuning</strong></a><sup id="fnref:NeurIPS2020assets"><a href="#fndef:NeurIPS2020assets" class=fnref >[6]</a></sup></p> <span class=fakeclass > at NeurIPS 2020 <em>with <a href="https://www.chrismusco.com/">Christopher Musco</a></em></span> <li><p><span class=link-hover-only > <a href="https://arxiv.org/abs/1901.09087"><strong>Optimality Implies Kernel Sum Classifiers are Statistically Efficient</strong></a></span><sup id="fnref:kernelsumassets"><a href="#fndef:kernelsumassets" class=fnref >[7]</a></sup></p> <span class=fakeclass > at ICML 2019 <em>with <a href="https://www.cs.purdue.edu/homes/jhonorio/">Jean Honorio</a></em></span> <li><p><span class=link-hover-only > <a href="https://www.cs.purdue.edu/homes/hmaji/papers/ISIT:JhaMajMey17.pdf"><strong>Characterizing Optimal Security and Round-Complexity for Secure OR Evaluation</strong></a></span></p> <span class=fakeclass > at ISIT 2017 <em>with Amisha Jhanji and <a href="https://www.cs.purdue.edu/homes/hmaji/">Hemanta K. Maji</a></em></span> </ol></div> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mphantom><mi mathvariant=normal >.</mi></mphantom></mrow><annotation encoding="application/x-tex">\phantom{.}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.10556em;vertical-align:0em;"></span><span class=mord  style="color:transparent;">.</span></span></span></span> <button class=theorem-accordion ><div class=theorem-accordion-text > <em>Presentation Assets</em> </div></button><div class=theorem-panel ><p></p> <p><table class=fndef  id="fndef:KronHutchinsonAssets"> <tr> <td class=fndef-backref ><a href="#fnref:KronHutchinsonAssets">[1]</a> <td class=fndef-content ><a href="/assets/kronHutchinsonSiamNNP20min.pdf">Slides</a> </table> <table class=fndef  id="fndef:SODA2024assets"> <tr> <td class=fndef-backref ><a href="#fnref:SODA2024assets">[2]</a> <td class=fndef-content >Code available on <a href="https://github.com/RaphaelArkadyMeyerNYU/SingleVectorKrylov">github</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/svkPurdue20minOneNote.pdf">Slides</a> </table> <table class=fndef  id="fndef:SODA2023assets"> <tr> <td class=fndef-backref ><a href="#fnref:SODA2023assets">[3]</a> <td class=fndef-content ><a href="/assets/chebyPandemicPresentationsBeamers.pdf">Slides</a> </table> <table class=fndef  id="fndef:ICLR2022assets"> <tr> <td class=fndef-backref ><a href="#fnref:ICLR2022assets">[4]</a> <td class=fndef-content ><a href="/assets/ICLR-2022-Poster.png">Poster</a> </table> <table class=fndef  id="fndef:hutchassets"> <tr> <td class=fndef-backref ><a href="#fnref:hutchassets">[5]</a> <td class=fndef-content >Code available on <a href="https://github.com/RaphaelArkadyMeyerNYU/hutchplusplus">github</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusposter.pdf">Landscape Poster</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusHalgPoster.pdf">Portrait Poster</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusHalg4minBeamers.pdf">4min Slides</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusSosa12minBeamers.pdf">12min Slides</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusSosa25minBeamers.pdf">25min Slides</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusVida35minBeamers.pdf">35min Slides</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/hutchplusplusJHU1hrBeamers.pdf">1hr Slides</a> </table> <table class=fndef  id="fndef:NeurIPS2020assets"> <tr> <td class=fndef-backref ><a href="#fnref:NeurIPS2020assets">[6]</a> <td class=fndef-content ><a href="/assets/NeurIPS-2020-Beamers.pdf">Slides</a> </table> <table class=fndef  id="fndef:kernelsumassets"> <tr> <td class=fndef-backref ><a href="#fnref:kernelsumassets">[7]</a> <td class=fndef-content ><a href="/assets/ICML-2019-Poster.pdf">Poster</a> <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo></mrow><annotation encoding="application/x-tex">\cdot</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.44445em;vertical-align:0em;"></span><span class=mord >⋅</span></span></span></span> <a href="/assets/ICML-2019-slides.pdf">Slides</a>. </table> </p></div> <h1 id=talks_presentations ><a href="#talks_presentations" class=header-anchor >Talks &amp; Presentations</a></h1> <p>To date, I have presented every paper I published at the associated conference. This is a list of other talks or presentations I have given.</p> <button class=theorem-accordion ><div class=theorem-accordion-text > Invited Talks </div></button><div class=theorem-panel ><p></p> <div class=link-hover-only ><ol> <li><p><strong>Optimal Trace Estimation and Sub-Optimal Kronecker-Trace Estimation</strong></p> <span class=fakeclass > at <a href="https://orecchia.net/event/theory-lunch/"><em>U Chicago Theory Lunch</em></a>.</span> <li><p><strong>On the Unreasonable Effectiveness of Single Vector Krylov for Low-Rank Approximation</strong></p> <span class=fakeclass > at <a href="https://www.birs.ca/events/2023/5-day-workshops/23w5108"><em>BIRS workshop on Perspectives on Matrix Computations</em></a>.</span> <li><p><strong>On the Unreasonable Effectiveness of Single Vector Krylov for Low-Rank Approximation</strong></p> <span class=fakeclass > at <em><a href="https://theorypurdue.wordpress.com/">Purdue University TCS Seminar</a></em></span> <li><p><strong>Near-Linear Sample Complexity for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.969438em;vertical-align:-0.286108em;"></span><span class=mord ><span class="mord mathnormal">L</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> Polynomial Regression</strong></p> <span class=fakeclass > at <em>NYU CDS Student Seminar</em></span> <li><p><strong>Hutch&#43;&#43; and More: Towards Optimal Spectral Sum Estimation</strong></p> <span class=fakeclass > at <em>Matrix Functions, Operator Functions, and Related Approximation Methods</em>, a minisymposium at SIAM Annual Meeting &#40;AN22&#41;</span> <li><p><strong>Hutch&#43;&#43;: Optimal Stochastic Trace Estimation</strong></p> <span class=fakeclass > at <em>John Hopkins University Theory Seminar</em></span> <li><p><strong>Lessons from Trace Estimation Lower Bounds: Testing, Communication, and Anti-Concentration</strong><sup id="fnref:SiamAN2021assets"><a href="#fndef:SiamAN2021assets" class=fnref >[8]</a></sup></p> <span class=fakeclass > at <em>Computational Lower Bounds in Numerical Linear Algebra</em>, a minisymposium at SIAM Annual Meeting &#40;AN21&#41;</span> </ol></div> <p><table class=fndef  id="fndef:SiamAN2021assets"> <tr> <td class=fndef-backref ><a href="#fnref:SiamAN2021assets">[8]</a> <td class=fndef-content >Slides available <a href="/assets/SiamAN-2021-Beamers.pdf">here</a>. Video starts at 1:04:55 <a href="https://player.vimeo.com/video/578316017#t&#61;1h4m55s">here</a>. </table> </p></div> <button class=theorem-accordion ><div class=theorem-accordion-text > Other Conference Presentations </div></button><div class=theorem-panel ><p></p> <div class=link-hover-only ><ol> <li><p><strong>On the Unreasonable Effectiveness of Single Vector Krylov for Low-Rank Approximation</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Short Talk at <a href="https://www.math.purdue.edu/~xiaj/FastSolvers2023/index.html">Conference on Fast Direct Solvers</a></span> <li><p><strong>Hutchinson&#39;s Estimator is Bad at Kronecker-Trace-Estimation</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Short Talk at <a href="/siam-nnp-minisymposium-2023"><em>SIAM-NNP 2022</em></a></span> <li><p><strong>On the Unreasonable Effectiveness of Single Vector Krylov for Low-Rank Approximation</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Short Talk at <a href="https://sites.google.com/view/gammanla2022/home"><em>GAMM ANLA 2022</em></a>.</span> <li><p><strong>Hutch&#43;&#43;: Optimal Stochastic Trace Estimation</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Poster and Short Talk at <a href="https://www.lse.ac.uk/HALG-2022"><em>HALG 2022</em></a>.</span> <li><p><strong>Chebyshev Sampling is Optimal for Lp Polynomial Regression</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Talk at <a href="/tcs_presentations"><em>NYU &quot;Pandemic Presentations&quot; 2022</em></a></span> <li><p><strong>Hutch&#43;&#43;: Optimal Stochastic Trace Estimation</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Poster at <a href="https://waldo2021.github.io/"><em>Wald&#40;O&#41; 2021</em></a>.</span> <li><p><strong>Optimality Implies Kernel Sum Classifiers are Statistically Efficient</strong><sup id="fnref:PresentationSectionAssets"><a href="#fndef:PresentationSectionAssets" class=fnref >[9]</a></sup></p> <span class=fakeclass > Poster at <em>Midwest Theory Day 2019</em></span> </ol></div> <p><table class=fndef  id="fndef:PresentationSectionAssets"> <tr> <td class=fndef-backref ><a href="#fnref:PresentationSectionAssets">[9]</a> <td class=fndef-content >Assets available in the <a href="#publications">Publications</a> section. </table> </p></div> <button class=theorem-accordion ><div class=theorem-accordion-text > Talks at Reading Groups </div></button><div class=theorem-panel ><p></p> <div class=link-hover-only ><ol> <li><p><strong>Fairwashing SHAP &#40;aka Interventional and Observational Shapley Values&#41;</strong><sup id="fnref:StoyanovichGroup2023"><a href="#fndef:StoyanovichGroup2023" class=fnref >[10]</a></sup></p> <span class=fakeclass > 45-min-long talk at NYU RAI Reading Group</span> <li><p><strong>The Equivalence of Matrix-Vector Complexity in Quantum Computing, Part 2</strong></p> <span class=fakeclass > 1-hour-long talk at NYU/UMass Quantum Linear Algebra Reading Group</span> <li><p><strong>The Equivalence of Matrix-Vector Complexity in Quantum Computing, Part 1</strong></p> <span class=fakeclass > 1-hour-long talk at NYU/UMass Quantum Linear Algebra Reading Group</span> <li><p><strong>Hutch&#43;&#43;: Optimal Stochastic Trace Estimation</strong></p> <span class=fakeclass > 1-hour-long talk at NYU VIDA RG Reading Group</span> <li><p><strong>Introduction to Leverage Scores</strong></p> <span class=fakeclass > 1.5-hour-long talk at NYU Tandon Theory Reading Group</span> <li><p><strong>Strategies for Episodic Tabular &amp; Linear MDPs</strong></p> <span class=fakeclass > Two 1.5-hour-long talks at NYU Tandon Reinforcement Learning Reading Group</span> <li><p><strong>Lagrangian Duality</strong></p> <span class=fakeclass > Three 1.5-hour-long talks at NYU Tandon Theory Reading Group</span> <li><p><strong>Introduction to Differential Entropy</strong></p> <span class=fakeclass > 1-hour-long talk at NYU CDS Reading Group on Information Theory</span> <li><p><strong>Lower bounds on the complexity of stochastic convex optimization</strong><sup id="fnref:MuscoGroup2019"><a href="#fndef:MuscoGroup2019" class=fnref >[11]</a></sup></p> <span class=fakeclass > 1-hour-long presentation of the paper <em>Information-Theoretic Lower Bounds on the Oracle Complexity of Stochastic Convex Optimization</em> by Agarwal et. al.</span> </ol></div> <p><table class=fndef  id="fndef:StoyanovichGroup2023"> <tr> <td class=fndef-backref ><a href="#fnref:StoyanovichGroup2023">[10]</a> <td class=fndef-content >Link to relevant paper <a href="https://arxiv.org/pdf/2006.16234.pdf">here</a>. My slides available <a href="/assets/StoyanovichGroup-2023-Beamers.pdf">here</a>. </table> <table class=fndef  id="fndef:MuscoGroup2019"> <tr> <td class=fndef-backref ><a href="#fnref:MuscoGroup2019">[11]</a> <td class=fndef-content >Link to the original paper <a href="https://arxiv.org/abs/1009.0571">here</a>. My slides available <a href="/assets/MuscoGroup-2019-Beamers.pdf">here</a>. </table> </p></div> <h1 id=teaching ><a href="#teaching" class=header-anchor >Teaching</a></h1> <p>I really enjoy teaching, and have been a TA for a few courses now:</p> <ul> <li><p><a href="https://www.chrismusco.com/amlds2023/">Algorithmic Machine Learning and Data Science</a>, New York University, Fall 2023</p> <li><p><a href="https://dataresponsibly.github.io/rds23/">Responsible Data Science</a>, New York University, Spring 2023</p> <li><p><a href="https://www.chrismusco.com/amlds2020/">Algorithmic Machine Learning and Data Science</a>, New York University, Fall 2020</p> <li><p><a href="https://www.chrismusco.com/introml2020/">Introduction to Machine Learning</a>, New York University, Spring 2020</p> <li><p><a href="https://www.cs.purdue.edu/homes/pdrineas/documents/CS381-Fall18/index.html">Introduction to the Analysis of Algorithms</a>, Purdue University, Fall 2018</p> </ul> <h1 id=service ><a href="#service" class=header-anchor >Service</a></h1> <p>Service outside of reviewing:</p> <ol> <li><p>Organizer for the <a href="/siam-nnp-minisymposium-2023">Minisymposium &quot;The Matrix-Vector Complexity of Linear Algebra&quot; at SIAM-NNP 2023</a></p> <li><p>Organizer for <a href="/tcs_presentations">NYU TCS &quot;Pandemic Presentations&quot; Day</a></p> <li><p>Organizer for NYU Tandon Theory Reading Group</p> </ol> <p>Service as a reviewer:</p> <ol> <li><p>ICLR 2024 Reviewer</p> <li><p>NeurIPS 2023 Reviewer</p> <li><p>TMLR 2023 Reviewer</p> <li><p>ICLR 2023 Reviewer</p> <li><p>SODA 2023 External Reviewer</p> <li><p>NeurIPS 2022 Reviewer</p> <li><p>ICML 2022 Reviewer</p> <li><p>STOC 2022 External Reviewer</p> <li><p>ICLR 2022 Reviewer*</p> <li><p>NeurIPS 2021 Reviewer*</p> <li><p>ISIT 2017 External Reviewer</p> </ol> <p><em>* Denotes Highlighted / Outstanding Reviewer</em></p> <script> var acc = document.getElementsByClassName("theorem-accordion"); var i; for (i = 0; i < acc.length; i++) { acc[i].addEventListener("click", function() { this.classList.toggle("active"); var panel = this.nextElementSibling; if (panel.style.maxHeight) { panel.style.maxHeight = null; } else { panel.style.maxHeight = panel.scrollHeight + "px"; } }); } </script> <div class=page-foot > <div class=copyright > &copy; Raphael Arkady Meyer. Last modified: November 29, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> using the tufte theme and the <a href="https://julialang.org">Julia programming language</a>. <a href="/disclaimer">NYU Hosting Disclaimer.</a> </div> </div> </div> </div> </div>